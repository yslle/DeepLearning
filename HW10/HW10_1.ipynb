{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"15-AAM1U_RtUYsaEyI8k1EHerObsBl7Yk","authorship_tag":"ABX9TyOI9hHuf42/L4zp3LYvYYSM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vN9Ux3p0-a4D","executionInfo":{"status":"ok","timestamp":1716478593710,"user_tz":-540,"elapsed":22027,"user":{"displayName":"이승연","userId":"15090960904061096098"}},"outputId":"e4adf7ee-1bee-47c9-adc8-3fbc03f5991f"},"outputs":[{"output_type":"stream","name":"stdout","text":["첫번째 입력:  버거킹 바삭한 신메뉴 3000원도 안되는 가격\n","첫번째 one-hot 출력:  [0. 1. 0.]\n","첫번째 토큰 결과:  [1, 2804, 41, 5168, 1512, 23]\n","학습셋 제목 최대 길이:  14\n","테스트셋 제목 최대 길이:  11\n","첫번째 패딩 토큰:  [   0    0    0    0    0    0    0    0    1 2804   41 5168 1512   23]\n","Word Size:  12464\n","Epoch 1/20\n","188/188 [==============================] - 2s 5ms/step - loss: 0.9016 - accuracy: 0.6455\n","Epoch 2/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.6518 - accuracy: 0.7222\n","Epoch 3/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.3963 - accuracy: 0.8513\n","Epoch 4/20\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9442\n","Epoch 5/20\n","188/188 [==============================] - 1s 5ms/step - loss: 0.1337 - accuracy: 0.9778\n","Epoch 6/20\n","188/188 [==============================] - 1s 6ms/step - loss: 0.0831 - accuracy: 0.9910\n","Epoch 7/20\n","188/188 [==============================] - 1s 6ms/step - loss: 0.0550 - accuracy: 0.9960\n","Epoch 8/20\n","188/188 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9977\n","Epoch 9/20\n","188/188 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9980\n","Epoch 10/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9992\n","Epoch 11/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0160 - accuracy: 0.9997\n","Epoch 12/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0126 - accuracy: 0.9997\n","Epoch 13/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 1.0000\n","Epoch 14/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n","Epoch 15/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 1.0000\n","Epoch 16/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 1.0000\n","Epoch 17/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 18/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 19/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 20/20\n","188/188 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n","47/47 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8840\n","\n"," Accuracy: 0.8840\n"]}],"source":["# -*- coding: utf-8 -*-\n","# 코드 내부에 한글을 사용\n","\n","import numpy\n","import pandas as pd\n","import tensorflow as tf\n","from numpy import array\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,Flatten,Embedding\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.text import text_to_word_sequence\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","from keras.utils import to_categorical\n","\n","# seed 값 설정\n","numpy.random.seed(3)\n","tf.random.set_seed(3)\n","\n","train_data = pd.read_csv('/content/drive/MyDrive/24-1 인공지능/080228-master/실습11_자료/train_mydataset_6000.csv', header=0, names=['title', 'label'])\n","X_train = train_data['title']\n","Y_train = train_data['label']\n","\n","test_data = pd.read_csv('/content/drive/MyDrive/24-1 인공지능/080228-master/실습11_자료/test_mydataset_1500.csv', header=0)\n","X_test = test_data['title']\n","Y_test = test_data['label']\n","\n","# 데이터 확인하기\n","print(\"첫번째 입력: \", X_train[0])\n","Y_train_onehot = to_categorical(Y_train)\n","Y_test_onehot = to_categorical(Y_test)\n","print(\"첫번째 one-hot 출력: \", Y_train_onehot[0])\n","\n","# 토큰화\n","token = Tokenizer()\n","token.fit_on_texts(X_train)\n","# print(token.word_index)\n","X_train_encoded = token.texts_to_sequences(X_train)\n","X_test_encoded = token.texts_to_sequences(X_test)\n","print(\"첫번째 토큰 결과: \", X_train_encoded[0])\n","\n","X_train_maxLen = max(len(l) for l in X_train_encoded)\n","print(\"학습셋 제목 최대 길이: \", X_train_maxLen)\n","X_test_maxLen = max(len(l) for l in X_test_encoded)\n","print(\"테스트셋 제목 최대 길이: \", X_test_maxLen)\n","\n","# 패딩, 서로 다른 길이의 데이터를 14로 맞춤\n","padded_X_train = pad_sequences(X_train_encoded, 14)\n","padded_X_test = pad_sequences(X_test_encoded, 14)\n","print(\"첫번째 패딩 토큰: \", padded_X_train[0])\n","\n","# 임베딩에 입력될 단어의 수 지정\n","word_size = len(token.word_index) +1\n","print(\"Word Size: \", word_size)\n","\n","# 단어 임베딩을 포함하여 딥러닝 모델을 만들고 결과를 출력\n","model = Sequential()\n","model.add(Embedding(word_size, 8, input_length=14))\n","model.add(Flatten())\n","model.add(Dense(3, activation='softmax'))\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # 다중 분류\n","model.fit(padded_X_train, Y_train_onehot, epochs=20)\n","print(\"\\n Accuracy: %.4f\" % (model.evaluate(padded_X_test, Y_test_onehot)[1]))"]}]}